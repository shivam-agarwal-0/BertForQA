{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -U transformers","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting transformers\n  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n\u001b[K     |████████████████████████████████| 769 kB 1.4 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.45.0)\nRequirement already satisfied, skipping upgrade: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.23.0)\nRequirement already satisfied, skipping upgrade: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.43)\nRequirement already satisfied, skipping upgrade: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2020.4.4)\nRequirement already satisfied, skipping upgrade: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.10)\nRequirement already satisfied, skipping upgrade: packaging in /opt/conda/lib/python3.7/site-packages (from transformers) (20.1)\nCollecting tokenizers==0.8.1.rc1\n  Downloading tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n\u001b[K     |████████████████████████████████| 3.0 MB 4.0 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: sentencepiece!=0.1.92 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.1.91)\nRequirement already satisfied, skipping upgrade: numpy in /opt/conda/lib/python3.7/site-packages (from transformers) (1.18.5)\nRequirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.24.3)\nRequirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\nRequirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.9)\nRequirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2020.6.20)\nRequirement already satisfied, skipping upgrade: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.14.0)\nRequirement already satisfied, skipping upgrade: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (0.14.1)\nRequirement already satisfied, skipping upgrade: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.1)\nRequirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\n\u001b[31mERROR: allennlp 1.0.0 has requirement transformers<2.12,>=2.9, but you'll have transformers 3.0.2 which is incompatible.\u001b[0m\nInstalling collected packages: tokenizers, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.7.0\n    Uninstalling tokenizers-0.7.0:\n      Successfully uninstalled tokenizers-0.7.0\n  Attempting uninstall: transformers\n    Found existing installation: transformers 2.11.0\n    Uninstalling transformers-2.11.0:\n      Successfully uninstalled transformers-2.11.0\nSuccessfully installed tokenizers-0.8.1rc1 transformers-3.0.2\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.1 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import random\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\ntqdm.pandas()\n\nfrom transformers import BertTokenizer, BertPreTrainedModel, BertConfig, BertModel\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader","execution_count":2,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/tqdm/std.py:666: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n  from pandas import Panel\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"random.seed(2020)\nnp.random.seed(2020)\ntorch.manual_seed(2020)\ntorch.cuda.manual_seed_all(2020)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_json_as_pandas_df(filename):\n    df = pd.read_json(f'/kaggle/input/squad-20/{filename}', orient='records')\n    df = pd.DataFrame.from_records(df['data'])\n    df = df.explode('paragraphs').reset_index(drop=True)\n    df['context'] = df['paragraphs'].apply(lambda x: x['context'])\n    df['qas'] = df['paragraphs'].apply(lambda x: x['qas'])\n    df = df[['title', 'context', 'qas']]\n    df = df.explode('qas').reset_index(drop=True)\n    df = pd.concat([df, pd.DataFrame.from_records(df['qas'])], axis=1).drop(['qas'], axis=1)\n    df.loc[df['is_impossible'], 'answers'] = df.loc[df['is_impossible'], 'plausible_answers']\n    df = df.drop(['plausible_answers'], axis=1)\n    df['answers'] = df['answers'].apply(lambda x: x[0] if len(x) else {})\n    return df","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = load_json_as_pandas_df('train-v2.0.json')\ntrain_df","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"          title                                            context  \\\n0       Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n1       Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n2       Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n3       Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n4       Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n...         ...                                                ...   \n130314   Matter  The term \"matter\" is used throughout physics i...   \n130315   Matter  The term \"matter\" is used throughout physics i...   \n130316   Matter  The term \"matter\" is used throughout physics i...   \n130317   Matter  The term \"matter\" is used throughout physics i...   \n130318   Matter  The term \"matter\" is used throughout physics i...   \n\n                                                 question  \\\n0                When did Beyonce start becoming popular?   \n1       What areas did Beyonce compete in when she was...   \n2       When did Beyonce leave Destiny's Child and bec...   \n3           In what city and state did Beyonce  grow up?    \n4              In which decade did Beyonce become famous?   \n...                                                   ...   \n130314  Physics has broadly agreed on the definition o...   \n130315               Who coined the term partonic matter?   \n130316              What is another name for anti-matter?   \n130317  Matter usually does not need to be used in con...   \n130318  What field of study has a variety of unusual c...   \n\n                              id  \\\n0       56be85543aeaaa14008c9063   \n1       56be85543aeaaa14008c9065   \n2       56be85543aeaaa14008c9066   \n3       56bf6b0f3aeaaa14008c9601   \n4       56bf6b0f3aeaaa14008c9602   \n...                          ...   \n130314  5a7e070b70df9f001a875439   \n130315  5a7e070b70df9f001a87543a   \n130316  5a7e070b70df9f001a87543b   \n130317  5a7e070b70df9f001a87543c   \n130318  5a7e070b70df9f001a87543d   \n\n                                                  answers  is_impossible  \n0       {'text': 'in the late 1990s', 'answer_start': ...          False  \n1       {'text': 'singing and dancing', 'answer_start'...          False  \n2                   {'text': '2003', 'answer_start': 526}          False  \n3         {'text': 'Houston, Texas', 'answer_start': 166}          False  \n4             {'text': 'late 1990s', 'answer_start': 276}          False  \n...                                                   ...            ...  \n130314            {'text': 'matter', 'answer_start': 485}           True  \n130315            {'text': 'Alfvén', 'answer_start': 327}           True  \n130316  {'text': 'Gk. common matter', 'answer_start': ...           True  \n130317  {'text': 'a specifying modifier', 'answer_star...           True  \n130318            {'text': 'physics', 'answer_start': 37}           True  \n\n[130319 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>context</th>\n      <th>question</th>\n      <th>id</th>\n      <th>answers</th>\n      <th>is_impossible</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Beyoncé</td>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>When did Beyonce start becoming popular?</td>\n      <td>56be85543aeaaa14008c9063</td>\n      <td>{'text': 'in the late 1990s', 'answer_start': ...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Beyoncé</td>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>What areas did Beyonce compete in when she was...</td>\n      <td>56be85543aeaaa14008c9065</td>\n      <td>{'text': 'singing and dancing', 'answer_start'...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Beyoncé</td>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>When did Beyonce leave Destiny's Child and bec...</td>\n      <td>56be85543aeaaa14008c9066</td>\n      <td>{'text': '2003', 'answer_start': 526}</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Beyoncé</td>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>In what city and state did Beyonce  grow up?</td>\n      <td>56bf6b0f3aeaaa14008c9601</td>\n      <td>{'text': 'Houston, Texas', 'answer_start': 166}</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Beyoncé</td>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>In which decade did Beyonce become famous?</td>\n      <td>56bf6b0f3aeaaa14008c9602</td>\n      <td>{'text': 'late 1990s', 'answer_start': 276}</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>130314</th>\n      <td>Matter</td>\n      <td>The term \"matter\" is used throughout physics i...</td>\n      <td>Physics has broadly agreed on the definition o...</td>\n      <td>5a7e070b70df9f001a875439</td>\n      <td>{'text': 'matter', 'answer_start': 485}</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>130315</th>\n      <td>Matter</td>\n      <td>The term \"matter\" is used throughout physics i...</td>\n      <td>Who coined the term partonic matter?</td>\n      <td>5a7e070b70df9f001a87543a</td>\n      <td>{'text': 'Alfvén', 'answer_start': 327}</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>130316</th>\n      <td>Matter</td>\n      <td>The term \"matter\" is used throughout physics i...</td>\n      <td>What is another name for anti-matter?</td>\n      <td>5a7e070b70df9f001a87543b</td>\n      <td>{'text': 'Gk. common matter', 'answer_start': ...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>130317</th>\n      <td>Matter</td>\n      <td>The term \"matter\" is used throughout physics i...</td>\n      <td>Matter usually does not need to be used in con...</td>\n      <td>5a7e070b70df9f001a87543c</td>\n      <td>{'text': 'a specifying modifier', 'answer_star...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>130318</th>\n      <td>Matter</td>\n      <td>The term \"matter\" is used throughout physics i...</td>\n      <td>What field of study has a variety of unusual c...</td>\n      <td>5a7e070b70df9f001a87543d</td>\n      <td>{'text': 'physics', 'answer_start': 37}</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>130319 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_df = load_json_as_pandas_df('dev-v2.0.json')\nvalid_df","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"         title                                            context  \\\n0      Normans  The Normans (Norman: Nourmands; French: Norman...   \n1      Normans  The Normans (Norman: Nourmands; French: Norman...   \n2      Normans  The Normans (Norman: Nourmands; French: Norman...   \n3      Normans  The Normans (Norman: Nourmands; French: Norman...   \n4      Normans  The Normans (Norman: Nourmands; French: Norman...   \n...        ...                                                ...   \n11868    Force  The pound-force has a metric counterpart, less...   \n11869    Force  The pound-force has a metric counterpart, less...   \n11870    Force  The pound-force has a metric counterpart, less...   \n11871    Force  The pound-force has a metric counterpart, less...   \n11872    Force  The pound-force has a metric counterpart, less...   \n\n                                                question  \\\n0                   In what country is Normandy located?   \n1                     When were the Normans in Normandy?   \n2          From which countries did the Norse originate?   \n3                              Who was the Norse leader?   \n4      What century did the Normans first gain their ...   \n...                                                  ...   \n11868  What is the seldom used force unit equal to on...   \n11869           What does not have a metric counterpart?   \n11870  What is the force exerted by standard gravity ...   \n11871  What force leads to a commonly used unit of mass?   \n11872        What force is part of the modern SI system?   \n\n                             id  \\\n0      56ddde6b9a695914005b9628   \n1      56ddde6b9a695914005b9629   \n2      56ddde6b9a695914005b962a   \n3      56ddde6b9a695914005b962b   \n4      56ddde6b9a695914005b962c   \n...                         ...   \n11868  5737aafd1c456719005744ff   \n11869  5ad28ad0d7d075001a4299cc   \n11870  5ad28ad0d7d075001a4299cd   \n11871  5ad28ad0d7d075001a4299ce   \n11872  5ad28ad0d7d075001a4299cf   \n\n                                                 answers  is_impossible  \n0                {'text': 'France', 'answer_start': 159}          False  \n1      {'text': '10th and 11th centuries', 'answer_st...          False  \n2      {'text': 'Denmark, Iceland and Norway', 'answe...          False  \n3                 {'text': 'Rollo', 'answer_start': 308}          False  \n4          {'text': '10th century', 'answer_start': 671}          False  \n...                                                  ...            ...  \n11868            {'text': 'sthène', 'answer_start': 665}          False  \n11869         {'text': 'pound-force', 'answer_start': 4}           True  \n11870     {'text': 'kilogram-force', 'answer_start': 82}           True  \n11871    {'text': 'kilogram-force', 'answer_start': 195}           True  \n11872    {'text': 'kilogram-force', 'answer_start': 383}           True  \n\n[11873 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>context</th>\n      <th>question</th>\n      <th>id</th>\n      <th>answers</th>\n      <th>is_impossible</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Normans</td>\n      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n      <td>In what country is Normandy located?</td>\n      <td>56ddde6b9a695914005b9628</td>\n      <td>{'text': 'France', 'answer_start': 159}</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Normans</td>\n      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n      <td>When were the Normans in Normandy?</td>\n      <td>56ddde6b9a695914005b9629</td>\n      <td>{'text': '10th and 11th centuries', 'answer_st...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Normans</td>\n      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n      <td>From which countries did the Norse originate?</td>\n      <td>56ddde6b9a695914005b962a</td>\n      <td>{'text': 'Denmark, Iceland and Norway', 'answe...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Normans</td>\n      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n      <td>Who was the Norse leader?</td>\n      <td>56ddde6b9a695914005b962b</td>\n      <td>{'text': 'Rollo', 'answer_start': 308}</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Normans</td>\n      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n      <td>What century did the Normans first gain their ...</td>\n      <td>56ddde6b9a695914005b962c</td>\n      <td>{'text': '10th century', 'answer_start': 671}</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11868</th>\n      <td>Force</td>\n      <td>The pound-force has a metric counterpart, less...</td>\n      <td>What is the seldom used force unit equal to on...</td>\n      <td>5737aafd1c456719005744ff</td>\n      <td>{'text': 'sthène', 'answer_start': 665}</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>11869</th>\n      <td>Force</td>\n      <td>The pound-force has a metric counterpart, less...</td>\n      <td>What does not have a metric counterpart?</td>\n      <td>5ad28ad0d7d075001a4299cc</td>\n      <td>{'text': 'pound-force', 'answer_start': 4}</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>11870</th>\n      <td>Force</td>\n      <td>The pound-force has a metric counterpart, less...</td>\n      <td>What is the force exerted by standard gravity ...</td>\n      <td>5ad28ad0d7d075001a4299cd</td>\n      <td>{'text': 'kilogram-force', 'answer_start': 82}</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>11871</th>\n      <td>Force</td>\n      <td>The pound-force has a metric counterpart, less...</td>\n      <td>What force leads to a commonly used unit of mass?</td>\n      <td>5ad28ad0d7d075001a4299ce</td>\n      <td>{'text': 'kilogram-force', 'answer_start': 195}</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>11872</th>\n      <td>Force</td>\n      <td>The pound-force has a metric counterpart, less...</td>\n      <td>What force is part of the modern SI system?</td>\n      <td>5ad28ad0d7d075001a4299cf</td>\n      <td>{'text': 'kilogram-force', 'answer_start': 383}</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>11873 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_len = 512\nepochs = 1\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')","execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"736707d166504bdcbccdc089907a5349"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# question + context tokens length\n\n# count    130319.000000\n# mean        170.726632\n# std          65.407215\n# min          35.000000\n# 25%         129.000000\n# 50%         158.000000\n# 75%         200.000000\n# max         870.000000\n# dtype: float64\n\n# Around 200 examples have token length of more than 500","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SQuAD2Dataset(Dataset):\n    def __init__(self, df, tokenizer, max_len):\n        self.df = df\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        \n    def __len__(self):\n        return len(self.df)\n        \n    def __getitem__(self, idx):\n        context = self.df['context'][idx]\n        question = self.df['question'][idx]\n        answer = self.df['answers'][idx]['text']\n        answer_start = self.df['answers'][idx]['answer_start']\n        is_impossible = self.df['is_impossible'][idx]\n        qas_id = self.df['id'][idx]\n        \n        input_text = '[CLS] ' + question + ' [SEP] ' + context + ' [SEP]'\n        input_tokens = self.tokenizer.tokenize(input_text)\n        \n        start_position = 0\n        end_position = 0\n        \n        if not is_impossible:\n            answer_tokens = self.tokenizer.tokenize(answer)\n            \n            for i, tok in enumerate(input_tokens):\n                if tok == answer_tokens[0] and input_tokens[min(len(input_tokens)-1, i+len(answer_tokens)-1)] == answer_tokens[-1]:\n                    start_position = i\n                    end_position = min(len(input_tokens)-1, i+len(answer_tokens)-1)\n\n        token_type_ids = [0] * (len(self.tokenizer.tokenize(question)) + 2)\n        token_type_ids = token_type_ids + [1] * (len(input_tokens) - len(token_type_ids))\n\n        input_ids = self.tokenizer.convert_tokens_to_ids(input_tokens)\n        attention_mask = [1] * len(input_tokens)\n\n        # Truncate\n        if len(input_ids) > self.max_len:\n            input_ids = input_ids[:self.max_len]\n            attention_mask = attention_mask[:self.max_len]\n            token_type_ids = token_type_ids[:self.max_len]\n            \n        # Padding\n        if len(input_ids) < self.max_len:\n            input_ids = input_ids + [0] * (max_len - len(input_tokens))\n            attention_mask = attention_mask + [0] * (max_len - len(input_tokens))\n            token_type_ids = token_type_ids + [0] * (max_len - len(input_tokens))\n        \n        # convert lists to tensor\n        input_ids = torch.tensor(input_ids, dtype=torch.long)\n        attention_mask = torch.tensor(attention_mask, dtype=torch.float)\n        token_type_ids = torch.tensor(token_type_ids, dtype=torch.long)\n        start_position = torch.tensor(start_position, dtype=torch.long).unsqueeze(0)\n        end_position = torch.tensor(end_position, dtype=torch.long).unsqueeze(0)\n        \n        return input_ids, attention_mask, token_type_ids, start_position, end_position","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = SQuAD2Dataset(train_df, tokenizer, max_len)\nvalid_dataset = SQuAD2Dataset(valid_df, tokenizer, max_len)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\nvalid_dataloader = DataLoader(valid_dataset, batch_size=8, shuffle=False)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SQuAD2Model(BertPreTrainedModel):\n    def __init__(self, conf):\n        super(SQuAD2Model, self).__init__(conf)\n        self.bert = BertModel(conf)\n        self.drop_out = nn.Dropout(0.1)\n        self.fc = nn.Linear(768 * 2, 2)\n    \n    def forward(self, ids, mask, token_type_ids):\n        _, _, out = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids)\n\n        out = torch.cat((out[-1], out[-2]), dim=-1)\n        out = self.drop_out(out)\n        logits = self.fc(out)\n\n        start_logits, end_logits = logits.split(1, dim=-1)\n\n        start_logits = start_logits.squeeze(-1)\n        end_logits = end_logits.squeeze(-1)\n\n        return start_logits, end_logits","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_config = BertConfig.from_pretrained('bert-base-uncased')\nmodel_config.output_hidden_states = True\nmodel = SQuAD2Model(conf=model_config)\nmodel.to(device)","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f5fb6021de2453fb7505a6d116fc717"}},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5)\ncriterion = nn.CrossEntropyLoss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in tqdm(range(epochs)):\n\n    model.train()\n\n    for step, batch in enumerate(train_dataloader):\n        optimizer.zero_grad()\n\n        input_ids, attention_masks, token_type_ids, start_positions, end_positions = batch\n        input_ids = input_ids.to(device)\n        attention_masks = attention_masks.to(device)\n        token_type_ids = token_type_ids.to(device)\n        start_positions = start_positions.squeeze().to(device)\n        end_positions = end_positions.squeeze().to(device)\n\n        outputs_start, outputs_end = model(input_ids, attention_masks, token_type_ids)\n\n        loss = criterion(outputs_start, start_positions) + criterion(outputs_end, end_positions)\n        loss.backward()\n\n        optimizer.step()\n        if (step+1) % 2500 == 0:\n            print(f'Epoch: {epoch+1} || Step: {step+1} || Training Loss: {loss.item()}')\n\n    model.eval()\n\n    true_start = []\n    true_end = []\n    pred_start = []\n    pred_end = []\n\n    with torch.no_grad():\n\n        for step, batch in enumerate(valid_dataloader):\n\n            input_ids, attention_masks, token_type_ids, start_positions, end_positions = batch\n            input_ids = input_ids.to(device)\n            attention_masks = attention_masks.to(device)\n            token_type_ids = token_type_ids.to(device)\n            start_positions = start_positions.squeeze().to(device)\n            end_positions = end_positions.squeeze().to(device)\n\n            outputs_start, outputs_end = model(input_ids, attention_masks, token_type_ids)\n\n            true_start.append(start_positions)\n            true_end.append(end_positions)\n            pred_start.append(outputs_start)\n            pred_end.append(outputs_end)\n\n    true_start = torch.cat(true_start)\n    true_end = torch.cat(true_end)\n    pred_start = torch.cat(pred_start)\n    pred_end = torch.cat(pred_end)\n    \n    loss = criterion(pred_start, true_start) + criterion(pred_end, true_end)\n        \n    print(f'Validation Loss: {loss.item()}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}